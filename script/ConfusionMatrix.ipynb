{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c36e036",
   "metadata": {},
   "source": [
    "# Confusion Matrix untuk Deteksi Dipstick\n",
    "Notebook ini untuk evaluasi model: apakah gambar terdeteksi ada dipstick (valid) atau background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577a90f7",
   "metadata": {},
   "source": [
    "## 1. Setup & Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1d3c96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _multiarray_umath: The specified module could not be found."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\cv2\\__init__.py:181\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra Python code for\u001b[39m\u001b[38;5;124m\"\u001b[39m, submodule, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis loaded\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOpenCV loader: DONE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 181\u001b[0m bootstrap()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\site-packages\\cv2\\__init__.py:153\u001b[0m, in \u001b[0;36mbootstrap\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelink everything from native cv2 module to cv2 package\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    151\u001b[0m py_module \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 153\u001b[0m native_module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv2\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m py_module\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28msetattr\u001b[39m(py_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_native\u001b[39m\u001b[38;5;124m\"\u001b[39m, native_module)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "\u001b[1;31mImportError\u001b[0m: numpy._core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c2bf6",
   "metadata": {},
   "source": [
    "## 2. Load Model & Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path ke model terbaik (sesuaikan dengan lokasi model kamu)\n",
    "MODEL_PATH = r'c:\\Users\\ACER\\Documents\\5 Magang\\Telkom\\Project-dipstick\\eksperimen-v11-3class\\best.pt'\n",
    "\n",
    "# Path ke data\n",
    "DATA_YAML = r'c:\\Users\\ACER\\Documents\\5 Magang\\Telkom\\Project-dipstick\\data\\data.yaml'\n",
    "DATASET_PATH = Path(r'c:\\Users\\ACER\\Documents\\5 Magang\\Telkom\\Project-dipstick\\data')\n",
    "\n",
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model = YOLO(MODEL_PATH)\n",
    "print(f\"✓ Model loaded from: {MODEL_PATH}\")\n",
    "\n",
    "# Load data config\n",
    "with open(DATA_YAML, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"\\nDataset Info:\")\n",
    "print(f\"  Classes: {data_config['names']}\")\n",
    "print(f\"  Number of classes: {data_config['nc']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a493c6",
   "metadata": {},
   "source": [
    "## 3. Prepare Ground Truth Labels\n",
    "Membaca label dari file txt untuk menentukan ground truth:\n",
    "- **Background**: file txt kosong (tidak ada objek)\n",
    "- **Dipstick (Valid)**: file txt ada isinya (ada objek terdeteksi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_labels(images_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Membaca ground truth dari label files\n",
    "    Returns: dict {image_name: 'dipstick' or 'background'}\n",
    "    \"\"\"\n",
    "    ground_truth = {}\n",
    "    \n",
    "    image_files = list(images_dir.glob('*'))\n",
    "    image_files = [f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        # Cari label file yang sesuai\n",
    "        label_file = labels_dir / f\"{img_file.stem}.txt\"\n",
    "        \n",
    "        if label_file.exists():\n",
    "            # Cek apakah file kosong (background) atau ada isinya (dipstick)\n",
    "            if label_file.stat().st_size == 0:\n",
    "                ground_truth[img_file.name] = 'background'\n",
    "            else:\n",
    "                ground_truth[img_file.name] = 'dipstick'\n",
    "        else:\n",
    "            # Jika tidak ada label file, anggap background\n",
    "            ground_truth[img_file.name] = 'background'\n",
    "    \n",
    "    return ground_truth\n",
    "\n",
    "# Get ground truth for test set\n",
    "test_images_dir = DATASET_PATH / 'test' / 'images'\n",
    "test_labels_dir = DATASET_PATH / 'test' / 'labels'\n",
    "\n",
    "print(\"Reading ground truth labels...\")\n",
    "ground_truth = get_ground_truth_labels(test_images_dir, test_labels_dir)\n",
    "\n",
    "# Statistics\n",
    "gt_df = pd.DataFrame(list(ground_truth.items()), columns=['image', 'true_label'])\n",
    "print(f\"\\nGround Truth Statistics:\")\n",
    "print(gt_df['true_label'].value_counts())\n",
    "print(f\"\\nTotal images: {len(ground_truth)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325bc51",
   "metadata": {},
   "source": [
    "## 4. Run Inference & Get Predictions\n",
    "Jalankan model pada semua gambar test untuk mendapatkan prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, images_dir, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Jalankan inference dan klasifikasikan gambar sebagai 'dipstick' atau 'background'\n",
    "    Jika ada deteksi dengan confidence >= threshold -> dipstick\n",
    "    Jika tidak ada deteksi -> background\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    image_files = list(images_dir.glob('*'))\n",
    "    image_files = [f for f in image_files if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "    \n",
    "    print(f\"Running inference on {len(image_files)} images...\")\n",
    "    \n",
    "    for img_file in tqdm(image_files):\n",
    "        # Run inference\n",
    "        results = model(str(img_file), conf=conf_threshold, verbose=False)\n",
    "        \n",
    "        # Cek apakah ada deteksi\n",
    "        if len(results[0].boxes) > 0:\n",
    "            predictions[img_file.name] = 'dipstick'\n",
    "        else:\n",
    "            predictions[img_file.name] = 'background'\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Set confidence threshold\n",
    "CONF_THRESHOLD = 0.25  # Sesuaikan jika perlu\n",
    "\n",
    "print(f\"Confidence threshold: {CONF_THRESHOLD}\")\n",
    "predictions = get_predictions(model, test_images_dir, conf_threshold=CONF_THRESHOLD)\n",
    "\n",
    "# Statistics\n",
    "pred_df = pd.DataFrame(list(predictions.items()), columns=['image', 'predicted_label'])\n",
    "print(f\"\\nPrediction Statistics:\")\n",
    "print(pred_df['predicted_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0b6697",
   "metadata": {},
   "source": [
    "## 5. Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea245db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine ground truth and predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'image': list(ground_truth.keys()),\n",
    "    'true_label': [ground_truth[img] for img in ground_truth.keys()],\n",
    "    'predicted_label': [predictions.get(img, 'background') for img in ground_truth.keys()]\n",
    "})\n",
    "\n",
    "# Create confusion matrix\n",
    "y_true = results_df['true_label']\n",
    "y_pred = results_df['predicted_label']\n",
    "\n",
    "# Define labels order\n",
    "labels = ['background', 'dipstick']\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix - Dipstick Detection\\n(Image-level Classification)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved as 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a13f03",
   "metadata": {},
   "source": [
    "## 6. Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_true, y_pred, labels=labels, target_names=labels))\n",
    "\n",
    "# Manual calculation\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED METRICS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"True Positives (TP):  {tp:4d}  - Correctly detected dipstick\")\n",
    "print(f\"True Negatives (TN):  {tn:4d}  - Correctly detected background\")\n",
    "print(f\"False Positives (FP): {fp:4d}  - Background predicted as dipstick\")\n",
    "print(f\"False Negatives (FN): {fn:4d}  - Dipstick predicted as background\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:    {accuracy:.4f}  ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision:   {precision:.4f}  ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:      {recall:.4f}  ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:    {f1_score:.4f}  ({f1_score*100:.2f}%)\")\n",
    "print(f\"Specificity: {specificity:.4f}  ({specificity*100:.2f}%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188d4a7",
   "metadata": {},
   "source": [
    "## 7. Analyze Errors\n",
    "Lihat gambar mana saja yang salah diprediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef3b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified images\n",
    "false_positives = results_df[(results_df['true_label'] == 'background') & \n",
    "                              (results_df['predicted_label'] == 'dipstick')]\n",
    "false_negatives = results_df[(results_df['true_label'] == 'dipstick') & \n",
    "                              (results_df['predicted_label'] == 'background')]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ERROR ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFalse Positives ({len(false_positives)}): Background diprediksi sebagai Dipstick\")\n",
    "if len(false_positives) > 0:\n",
    "    print(\"Sample images:\")\n",
    "    for idx, row in false_positives.head(10).iterrows():\n",
    "        print(f\"  - {row['image']}\")\n",
    "\n",
    "print(f\"\\nFalse Negatives ({len(false_negatives)}): Dipstick diprediksi sebagai Background\")\n",
    "if len(false_negatives) > 0:\n",
    "    print(\"Sample images:\")\n",
    "    for idx, row in false_negatives.head(10).iterrows():\n",
    "        print(f\"  - {row['image']}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('prediction_results.csv', index=False)\n",
    "false_positives.to_csv('false_positives.csv', index=False)\n",
    "false_negatives.to_csv('false_negatives.csv', index=False)\n",
    "\n",
    "print(\"\\n✓ Results saved to CSV files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0b22",
   "metadata": {},
   "source": [
    "## 8. Visualize Sample Predictions\n",
    "Visualisasi beberapa contoh prediksi (benar dan salah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(df, category, n_samples=4):\n",
    "    \"\"\"\n",
    "    Visualize sample images from a specific category\n",
    "    \"\"\"\n",
    "    if len(df) == 0:\n",
    "        print(f\"No samples found for {category}\")\n",
    "        return\n",
    "    \n",
    "    samples = df.head(n_samples)\n",
    "    n = len(samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n, figsize=(5*n, 5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (_, row) in enumerate(samples.iterrows()):\n",
    "        img_path = test_images_dir / row['image']\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(f\"True: {row['true_label']}\\nPred: {row['predicted_label']}\", \n",
    "                            fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{category} Samples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{category.lower().replace(\" \", \"_\")}_samples.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize different categories\n",
    "print(\"Visualizing False Positives...\")\n",
    "visualize_samples(false_positives, \"False Positives\", n_samples=4)\n",
    "\n",
    "print(\"\\nVisualizing False Negatives...\")\n",
    "visualize_samples(false_negatives, \"False Negatives\", n_samples=4)\n",
    "\n",
    "# True Positives\n",
    "true_positives = results_df[(results_df['true_label'] == 'dipstick') & \n",
    "                             (results_df['predicted_label'] == 'dipstick')]\n",
    "print(\"\\nVisualizing True Positives...\")\n",
    "visualize_samples(true_positives, \"True Positives (Correct)\", n_samples=4)\n",
    "\n",
    "# True Negatives\n",
    "true_negatives = results_df[(results_df['true_label'] == 'background') & \n",
    "                             (results_df['predicted_label'] == 'background')]\n",
    "print(\"\\nVisualizing True Negatives...\")\n",
    "visualize_samples(true_negatives, \"True Negatives (Correct)\", n_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6548a",
   "metadata": {},
   "source": [
    "## 9. Test Different Confidence Thresholds (Optional)\n",
    "Coba berbagai confidence threshold untuk melihat dampaknya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd82965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = [0.1, 0.2, 0.25, 0.3, 0.4, 0.5]\n",
    "threshold_results = []\n",
    "\n",
    "print(\"Testing different confidence thresholds...\\n\")\n",
    "\n",
    "for thresh in thresholds:\n",
    "    print(f\"Testing threshold: {thresh}\")\n",
    "    preds = get_predictions(model, test_images_dir, conf_threshold=thresh)\n",
    "    \n",
    "    y_pred_temp = [preds.get(img, 'background') for img in ground_truth.keys()]\n",
    "    cm_temp = confusion_matrix(y_true, y_pred_temp, labels=labels)\n",
    "    tn, fp, fn, tp = cm_temp.ravel()\n",
    "    \n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'threshold': thresh,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1_score': f1,\n",
    "        'TP': tp,\n",
    "        'TN': tn,\n",
    "        'FP': fp,\n",
    "        'FN': fn\n",
    "    })\n",
    "\n",
    "# Create comparison dataframe\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THRESHOLD COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(threshold_df.to_string(index=False))\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "titles = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    axes[row, col].plot(threshold_df['threshold'], threshold_df[metric], \n",
    "                        marker='o', linewidth=2, markersize=8)\n",
    "    axes[row, col].set_xlabel('Confidence Threshold', fontsize=11)\n",
    "    axes[row, col].set_ylabel(title, fontsize=11)\n",
    "    axes[row, col].set_title(title, fontsize=12, fontweight='bold')\n",
    "    axes[row, col].grid(True, alpha=0.3)\n",
    "    axes[row, col].set_ylim([0, 1.05])\n",
    "\n",
    "plt.suptitle('Metrics vs Confidence Threshold', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save to CSV\n",
    "threshold_df.to_csv('threshold_comparison.csv', index=False)\n",
    "print(\"\\n✓ Threshold comparison saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d953c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Notebook ini menghasilkan:\n",
    "1. **Confusion Matrix** - Visualisasi performa klasifikasi\n",
    "2. **Metrics** - Accuracy, Precision, Recall, F1-Score, Specificity\n",
    "3. **Error Analysis** - Daftar gambar yang salah diprediksi (FP & FN)\n",
    "4. **Sample Visualizations** - Contoh gambar dari setiap kategori\n",
    "5. **Threshold Analysis** - Perbandingan performa di berbagai confidence threshold\n",
    "\n",
    "File output yang dihasilkan:\n",
    "- `confusion_matrix.png`\n",
    "- `prediction_results.csv`\n",
    "- `false_positives.csv`\n",
    "- `false_negatives.csv`\n",
    "- `threshold_comparison.png`\n",
    "- `threshold_comparison.csv`\n",
    "- `*_samples.png` (visualisasi sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
